{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import struct\n",
    "\n",
    "FILE_TRAIN_IMG = 'MNIST/train-images.idx3-ubyte'\n",
    "FILE_TRAIN_LBL = 'MNIST/train-labels.idx1-ubyte'\n",
    "FILE_TEST_IMG = 'MNIST/t10k-images.idx3-ubyte'\n",
    "FILE_TEST_LBL = 'MNIST/t10k-labels.idx1-ubyte'\n",
    "\n",
    "with open(FILE_TRAIN_IMG, 'rb') as f:\n",
    "    magic, size = struct.unpack(\">II\", f.read(8))\n",
    "    nrows, ncols = struct.unpack(\">II\", f.read(8))\n",
    "    data = np.fromfile(f, dtype=np.dtype(np.uint8).newbyteorder('>'))\n",
    "    # show the first digit\n",
    "    # data = data.reshape((size, nrows, ncols))\n",
    "    # plt.imshow(data[0], cmap='gray')\n",
    "    # plt.show()\n",
    "    data = data.reshape((size, nrows * ncols))\n",
    "    m, n = data.shape # m: num of rows n: num of pixels\n",
    "    data = data.T\n",
    "    data = data / 255.\n",
    "\n",
    "# open the label file for validation\n",
    "with open(FILE_TRAIN_LBL,'rb') as f:\n",
    "    magic, size = struct.unpack(\">II\", f.read(8))\n",
    "    labels = np.fromfile(f, dtype=np.dtype(np.uint8).newbyteorder('>'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer 0: input layer\n",
    "#   784 nodes - 1 per pixel\n",
    "# layer 1: hidden layer\n",
    "#   10 nodes - 1 per digit\n",
    "# layer 2: output layer\n",
    "#   10 nodes - 1 per digit\n",
    "\n",
    "# Training the network\n",
    "# 1) Forward propagation\n",
    "#   A[0] = x; // pass an image through the network and compute output\n",
    "#   Z[1] = W[1]A[0] + b[1]; // multiply by a weight and add a constant bias\n",
    "#   activation function - w/o this step, each node would just be a linear combination of the previous nodes\n",
    "#   tansh or sigmoid function are common activation functions - but we'll use relu\n",
    "#   relu - rectified linear unit - g(x) = x > 0 ? x : 0;\n",
    "#   A[1] = relu(Z[1])\n",
    "#   another activation function\n",
    "#   softmax - pick the best of our options for the output layer\n",
    "#   softmax(node z) = (e^z) / (sum(e^z)); // weight of current node divided by the total weight of all nodes\n",
    "\n",
    "# generate random arrays of floats for weights and biases\n",
    "# subtract 0.5 to normalize over -0.5 - 0.5\n",
    "def init_params():\n",
    "    W1 = np.random.rand(10, 784) - 0.5\n",
    "    b1 = np.random.rand(10, 1) - 0.5\n",
    "    W2 = np.random.rand(10, 10) - 0.5\n",
    "    b2 = np.random.rand(10, 1) - 0.5\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "def relu(Z):\n",
    "    return np.maximum(Z, 0)\n",
    "\n",
    "def relu_deriv(Z):\n",
    "    return Z > 0\n",
    "\n",
    "def softmax(Z):\n",
    "    return np.exp(Z) / sum(np.exp(Z))\n",
    "\n",
    "def forward_prop(W1, b1, W2, b2, X):\n",
    "    Z1 = W1.dot(X) + b1\n",
    "    A1 = relu(Z1)\n",
    "    Z2 = W2.dot(A1) + b2\n",
    "    A2 = softmax(Z2)\n",
    "    return Z1, A1, Z2, A2\n",
    "\n",
    "# \"one-hot encoding\" create a 1xm matrix with only one \"bit\" flipped\n",
    "# Y will be our labels matrix\n",
    "def one_hot(Y):\n",
    "    one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n",
    "    one_hot_Y[np.arange(Y.size), Y] = 1\n",
    "    return one_hot_Y.T\n",
    "\n",
    "# 2) Backwards propagation\n",
    "#   find the error across layers\n",
    "#   let dZ[2] be the error of the 2nd layer\n",
    "#   dZ[2] = A - Y\n",
    "#   dW[2] = 1/m * dZ[2]A[1]T\n",
    "#   db[2] = 1/m * sum(dz[2])\n",
    "#   dZ[1] = W[2]T * dZ[2] .* g'(Z[0]) // g' is the derivative of the activation function g(x)\n",
    "#   dW[1] = 1/m * dZ[1] * XT\n",
    "#   db[1] = 1/m * sum(dZ[1])\n",
    "\n",
    "# A2: our predictions\n",
    "def backward_prop(Z1, A1, A2, W2, X, Y):\n",
    "    one_hot_Y = one_hot(Y)\n",
    "    dZ2 = A2 - one_hot_Y\n",
    "    dW2 = 1/m * dZ2.dot(A1.T)\n",
    "    db2 = 1/m * np.sum(dZ2)\n",
    "    dZ1 = W2.T.dot(dZ2) * relu_deriv(Z1)\n",
    "    dW1 = 1/m * dZ1.dot(X.T)\n",
    "    db1 = 1/m * np.sum(dZ1)\n",
    "    return dW1, db1, dW2, db2\n",
    "\n",
    "# 3) Update parameters\n",
    "#   W[1] = W[1] - a * dW[1]\n",
    "#   b[1] = b[1] - a * db[1]\n",
    "#   w[2] = W[2] - a * dW[2]\n",
    "#   b[2] = b[2] - a * db[2]\n",
    "#   where a is some learning rate. this is a parameter you set, not gradient descent\n",
    "\n",
    "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha):\n",
    "    W1 = W1 - alpha * dW1\n",
    "    b1 = b1 - alpha * db1\n",
    "    W2 = W2 - alpha * dW2\n",
    "    b2 = b2 - alpha * db2\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "def get_predictions(A2):\n",
    "    return np.argmax(A2, 0)\n",
    "\n",
    "def get_accuracy(predictions, Y):\n",
    "    print(predictions, Y)\n",
    "    return np.sum(predictions == Y) / Y.size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the fun part\n",
    "def gradient_descent(W1, b1, W2, b2, X, Y, alpha, iterations):\n",
    "    \"\"\"X: our training data\n",
    "    Y: the labels for the data\n",
    "    alpha: learning rate\n",
    "    iterations: number of iterations\"\"\"\n",
    "    for i in range(iterations): # main training loop\n",
    "        Z1, A1, _, A2 = forward_prop(W1, b1, W2, b2, X)\n",
    "        dW1, db1, dW2, db2 = backward_prop(Z1, A1, A2, W2, X, Y)\n",
    "        W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha)\n",
    "        if i % (iterations // 20) == 0:\n",
    "            print(\"Iteration: \", i)\n",
    "            predictions = get_predictions(A2)\n",
    "            print(get_accuracy(predictions, Y))\n",
    "    print(\"Training complete.\")\n",
    "    print(get_accuracy(get_predictions(A2), Y))\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "def test(W1, b1, W2, b2, X, Y):\n",
    "    _, _, _, A2 = forward_prop(W1, b1, W2, b2, X)\n",
    "    print(\"Testing complete.\")\n",
    "    print(get_accuracy(get_predictions(A2), Y), \"final accuracy.\")\n",
    "\n",
    "def make_predictions(W1, b1, W2, b2, X):\n",
    "    _, _, _, A2 = forward_prop(W1, b1, W2, b2, X)\n",
    "    return get_predictions(A2)\n",
    "\n",
    "def test_prediction(index, W1, b1, W2, b2, X, Y):\n",
    "    current_image = X[:, index, None]\n",
    "    prediction = make_predictions(W1, b1, W2, b2, current_image)\n",
    "    label = Y[index]\n",
    "    print(\"Prediction:\", prediction)\n",
    "    print(\"Label:\", label)\n",
    "    current_image = current_image.reshape((28, 28)) * 255\n",
    "    plt.gray()\n",
    "    plt.imshow(current_image, interpolation='nearest')\n",
    "    plt.show()\n",
    "\n",
    "with open(FILE_TEST_IMG, 'rb') as f:\n",
    "    magic, size = struct.unpack(\">II\", f.read(8))\n",
    "    nrows, ncols = struct.unpack(\">II\", f.read(8))\n",
    "    test_data = np.fromfile(f, dtype=np.dtype(np.uint8).newbyteorder('>'))\n",
    "    test_data = test_data.reshape((size, nrows * ncols))\n",
    "    test_data = test_data.T\n",
    "    test_data = test_data / 255.\n",
    "\n",
    "with open(FILE_TEST_LBL,'rb') as f:\n",
    "    magic, size = struct.unpack(\">II\", f.read(8))\n",
    "    test_labels = np.fromfile(f, dtype=np.dtype(np.uint8).newbyteorder('>'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "[9 8 9 ... 0 9 9] [5 0 4 ... 5 6 8]\n",
      "0.07138333333333333\n",
      "Iteration:  25\n",
      "[3 0 4 ... 3 0 9] [5 0 4 ... 5 6 8]\n",
      "0.3862833333333333\n",
      "Iteration:  50\n",
      "[3 0 4 ... 3 0 8] [5 0 4 ... 5 6 8]\n",
      "0.5562833333333334\n",
      "Iteration:  75\n",
      "[3 0 4 ... 5 0 8] [5 0 4 ... 5 6 8]\n",
      "0.6648833333333334\n",
      "Iteration:  100\n",
      "[3 0 4 ... 5 0 8] [5 0 4 ... 5 6 8]\n",
      "0.7190833333333333\n",
      "Iteration:  125\n",
      "[3 0 4 ... 5 0 8] [5 0 4 ... 5 6 8]\n",
      "0.75495\n",
      "Iteration:  150\n",
      "[3 0 4 ... 5 0 8] [5 0 4 ... 5 6 8]\n",
      "0.77905\n",
      "Iteration:  175\n",
      "[3 0 4 ... 5 0 8] [5 0 4 ... 5 6 8]\n",
      "0.7973166666666667\n",
      "Iteration:  200\n",
      "[3 0 4 ... 5 0 8] [5 0 4 ... 5 6 8]\n",
      "0.8122333333333334\n",
      "Iteration:  225\n",
      "[3 0 4 ... 5 0 8] [5 0 4 ... 5 6 8]\n",
      "0.82495\n",
      "Iteration:  250\n",
      "[3 0 4 ... 5 0 8] [5 0 4 ... 5 6 8]\n",
      "0.8355\n",
      "Iteration:  275\n",
      "[3 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "0.8453833333333334\n",
      "Iteration:  300\n",
      "[3 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "0.8526333333333334\n",
      "Iteration:  325\n",
      "[3 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "0.8590166666666667\n",
      "Iteration:  350\n",
      "[3 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "0.8640333333333333\n",
      "Iteration:  375\n",
      "[3 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "0.8679166666666667\n",
      "Iteration:  400\n",
      "[3 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "0.8713166666666666\n",
      "Iteration:  425\n",
      "[3 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "0.8739166666666667\n",
      "Iteration:  450\n",
      "[3 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "0.87625\n",
      "Iteration:  475\n",
      "[3 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "0.8793\n",
      "Training complete.\n",
      "[3 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "0.8808166666666667\n"
     ]
    }
   ],
   "source": [
    "W1, b1, W2, b2 = init_params()\n",
    "W1, b1, W2, b2 = gradient_descent(W1, b1, W2, b2, data, labels, 0.2, 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing complete.\n",
      "[7 2 1 ... 4 5 6] [7 2 1 ... 4 5 6]\n",
      "0.8809 final accuracy.\n"
     ]
    }
   ],
   "source": [
    "test(W1, b1, W2, b2, test_data, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [4]\n",
      "Label: 4\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_prediction(6, W1, b1, W2, b2, test_data, test_labels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
